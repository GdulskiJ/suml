{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-14T21:57:35.825285Z",
     "start_time": "2026-01-14T21:57:16.530809Z"
    }
   },
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# Wczytanie i przygotowanie danych\n",
    "# =========================\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"european_capitals_history_clean.csv\",\n",
    "    parse_dates=[\"date\"]\n",
    ")\n",
    "\n",
    "df_city = df[df['city'] == 'Warszawa']\n",
    "df_city = df_city[['date', 'city', 'tavg']]\n",
    "df_city.sort_values(by=[\"date\"], inplace=True)\n",
    "\n",
    "# =========================\n",
    "# Tworzenie sekwencji czasowych\n",
    "# =========================\n",
    "\n",
    "def create_sequences(df, window=5):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(df) - window):\n",
    "        seq = df.iloc[i:i + window]['tavg'].values\n",
    "        label = df.iloc[i + window]['tavg']  # Temperatura na kolejny dzień\n",
    "\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "\n",
    "sequences, labels = create_sequences(df_city, window=5)\n",
    "\n",
    "# =========================\n",
    "# Normalizacja danych\n",
    "# =========================\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "sequences_scaled = scaler.fit_transform(\n",
    "    sequences.reshape(-1, 1)\n",
    ").reshape(sequences.shape)\n",
    "\n",
    "labels_scaled = scaler.transform(labels.reshape(-1, 1))\n",
    "\n",
    "# Reshape do LSTM: (samples, time_steps, features)\n",
    "sequences_scaled = sequences_scaled.reshape(\n",
    "    (sequences_scaled.shape[0], sequences_scaled.shape[1], 1)\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Podział na zbiór treningowy i testowy\n",
    "# =========================\n",
    "\n",
    "train_size = int(len(sequences_scaled) * 0.8)\n",
    "\n",
    "X_train = sequences_scaled[:train_size]\n",
    "X_test  = sequences_scaled[train_size:]\n",
    "\n",
    "y_train = labels_scaled[:train_size]\n",
    "y_test  = labels_scaled[train_size:]\n",
    "\n",
    "# =========================\n",
    "# Budowa modelu LSTM\n",
    "# =========================\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    LSTM(\n",
    "        units=50,\n",
    "        return_sequences=False,\n",
    "        input_shape=(X_train.shape[1], 1)\n",
    "    )\n",
    ")\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Trenowanie modelu\n",
    "# =========================\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "# =========================\n",
    "# Zapis modelu do folderu \"models\"\n",
    "# =========================\n",
    "\n",
    "model_dir = \"models\"\n",
    "model_path = os.path.join(model_dir, \"lstm_warszawa_temperature.keras\")\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model.save(model_path)\n",
    "\n",
    "print(f\"Model zapisany w lokalizacji: {model_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Wizualizacja funkcji straty\n",
    "# =========================\n",
    "\n",
    "plt.plot(history.history['loss'], label='Trening')\n",
    "plt.plot(history.history['val_loss'], label='Walidacja')\n",
    "plt.legend()\n",
    "plt.title(\"Strata modelu podczas treningu\")\n",
    "plt.xlabel(\"Epoka\")\n",
    "plt.ylabel(\"Strata\")\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# Predykcja na zbiorze testowym\n",
    "# =========================\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "y_test_rescaled = scaler.inverse_transform(y_test)\n",
    "\n",
    "plt.plot(y_test_rescaled, label='Rzeczywiste wartości')\n",
    "plt.plot(predictions_rescaled, label='Prognozy')\n",
    "plt.legend()\n",
    "plt.title(\"Porównanie prognoz i rzeczywistych wartości\")\n",
    "plt.xlabel(\"Próbka\")\n",
    "plt.ylabel(\"Średnia temperatura\")\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# Prognoza na 5 dni w przyszłość\n",
    "# =========================\n",
    "\n",
    "future_predictions = []\n",
    "input_sequence = X_test[-1]  # (5, 1)\n",
    "\n",
    "for _ in range(5):\n",
    "    pred_scaled = model.predict(\n",
    "        input_sequence.reshape(1, 5, 1)\n",
    "    )\n",
    "\n",
    "    future_predictions.append(pred_scaled[0][0])\n",
    "\n",
    "    # Przesunięcie okna czasowego\n",
    "    input_sequence = np.roll(input_sequence, -1)\n",
    "    input_sequence[-1] = pred_scaled\n",
    "\n",
    "future_predictions_rescaled = scaler.inverse_transform(\n",
    "    np.array(future_predictions).reshape(-1, 1)\n",
    ")\n",
    "\n",
    "print(\"Prognozy na 5 dni do przodu (średnia temperatura):\")\n",
    "print(future_predictions_rescaled)\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T21:57:35.829800Z",
     "start_time": "2026-01-14T21:57:35.826284Z"
    }
   },
   "cell_type": "code",
   "source": "print(model.summary)",
   "id": "f71da7c2aa4a4bb6",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T22:07:27.001879Z",
     "start_time": "2026-01-14T22:06:50.076133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# =========================\n",
    "# Funkcja budująca model LSTM\n",
    "# =========================\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        LSTM(\n",
    "            units=50,\n",
    "            return_sequences=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    )\n",
    "    model.add(Dense(1))\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# Funkcja MAPE\n",
    "# =========================\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Time Series Cross-Validation\n",
    "# =========================\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "rmse_scores = []\n",
    "mae_scores  = []\n",
    "mse_scores  = []\n",
    "r2_scores   = []\n",
    "mape_scores = []\n",
    "\n",
    "fold = 1\n",
    "\n",
    "for train_index, test_index in tscv.split(sequences_scaled):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "\n",
    "    X_train = sequences_scaled[train_index]\n",
    "    X_test  = sequences_scaled[test_index]\n",
    "\n",
    "    y_train = labels_scaled[train_index]\n",
    "    y_test  = labels_scaled[test_index]\n",
    "\n",
    "    model = build_lstm_model(\n",
    "        input_shape=(X_train.shape[1], 1)\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        verbose=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Odwrócenie skalowania\n",
    "    y_test_rescaled = scaler.inverse_transform(y_test)\n",
    "    y_pred_rescaled = scaler.inverse_transform(y_pred)\n",
    "\n",
    "    mse  = mean_squared_error(y_test_rescaled, y_pred_rescaled)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae  = mean_absolute_error(y_test_rescaled, y_pred_rescaled)\n",
    "    r2   = r2_score(y_test_rescaled, y_pred_rescaled)\n",
    "\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "  \n",
    "\n",
    "    print(\n",
    "        f\"R²: {r2:.4f} | \"\n",
    "        f\"MAE: {mae:.4f} | \"\n",
    "        f\"MSE: {mse:.4f} | \"\n",
    "        f\"RMSE: {rmse:.4f} | \"\n",
    "      \n",
    "    )\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# =========================\n",
    "# Podsumowanie\n",
    "# =========================\n",
    "\n",
    "print(\"\\nWalk-Forward Cross-Validation — LSTM\")\n",
    "print(f\"R²   : {np.mean(r2_scores):.4f}\")\n",
    "print(f\"MAE  : {np.mean(mae_scores):.4f}\")\n",
    "print(f\"MSE  : {np.mean(mse_scores):.4f}\")\n",
    "print(f\"RMSE : {np.mean(rmse_scores):.4f}\")\n",
    "\n"
   ],
   "id": "5da915e71938a136",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T22:09:07.789579Z",
     "start_time": "2026-01-14T22:09:07.264487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Obliczenie residuals\n",
    "# =========================\n",
    "residuals = y_test_rescaled - predictions_rescaled\n",
    "\n",
    "# =========================\n",
    "# Wykres residuals w czasie\n",
    "# =========================\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df_city['date'].iloc[-len(residuals):], residuals, marker='o', linestyle='-', color='b')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('Residuals modelu LSTM — błąd predykcji w czasie')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Błąd (°C)')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# Histogram residuals\n",
    "# =========================\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(residuals, kde=True, color='b')\n",
    "plt.title('Rozkład residuals modelu LSTM')\n",
    "plt.xlabel('Błąd predykcji (°C)')\n",
    "plt.ylabel('Częstość')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "7098cc737279e84c",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "1cced221b8138af8",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
