{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T22:23:11.607310Z",
     "start_time": "2026-01-14T22:22:26.535395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# Wczytanie i przygotowanie danych\n",
    "# =========================\n",
    "df = pd.read_csv(\n",
    "    \"european_capitals_history_clean.csv\",\n",
    "    parse_dates=[\"date\"]\n",
    ")\n",
    "\n",
    "df_city = df[df['city'] == 'Warszawa']\n",
    "df_city = df_city[['date', 'city', 'tavg']]\n",
    "df_city.sort_values(by=[\"date\"], inplace=True)\n",
    "\n",
    "# =========================\n",
    "# Tworzenie sekwencji czasowych\n",
    "# =========================\n",
    "def create_sequences(df, window=5):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(df) - window):\n",
    "        seq = df.iloc[i:i + window]['tavg'].values\n",
    "        label = df.iloc[i + window]['tavg']\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "sequences, labels = create_sequences(df_city, window=5)\n",
    "\n",
    "# =========================\n",
    "# Normalizacja danych\n",
    "# =========================\n",
    "scaler = MinMaxScaler()\n",
    "sequences_scaled = scaler.fit_transform(sequences.reshape(-1, 1)).reshape(sequences.shape)\n",
    "labels_scaled = scaler.transform(labels.reshape(-1, 1))\n",
    "sequences_scaled = sequences_scaled.reshape((sequences_scaled.shape[0], sequences_scaled.shape[1], 1))\n",
    "\n",
    "# =========================\n",
    "# Podział na zbiór treningowy i testowy\n",
    "# =========================\n",
    "train_size = int(len(sequences_scaled) * 0.8)\n",
    "X_train = sequences_scaled[:train_size]\n",
    "X_test  = sequences_scaled[train_size:]\n",
    "y_train = labels_scaled[:train_size]\n",
    "y_test  = labels_scaled[train_size:]\n",
    "\n",
    "# =========================\n",
    "# Budowa modelu LSTM z dwiema warstwami\n",
    "# =========================\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=32, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# =========================\n",
    "# EarlyStopping\n",
    "# =========================\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Trenowanie modelu\n",
    "# =========================\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,           # można zwiększyć liczbę epok, EarlyStopping zatrzyma trening wcześniej\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Zapis modelu\n",
    "# =========================\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_path = os.path.join(model_dir, \"lstm_warszawa_2layers.keras\")\n",
    "model.save(model_path)\n",
    "print(f\"Model zapisany w: {model_path}\")\n",
    "\n",
    "# =========================\n",
    "# Wizualizacja straty\n",
    "# =========================\n",
    "plt.plot(history.history['loss'], label='Trening')\n",
    "plt.plot(history.history['val_loss'], label='Walidacja')\n",
    "plt.legend()\n",
    "plt.title(\"Strata modelu podczas treningu\")\n",
    "plt.xlabel(\"Epoka\")\n",
    "plt.ylabel(\"Strata\")\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# Predykcja na zbiorze testowym\n",
    "# =========================\n",
    "predictions = model.predict(X_test)\n",
    "predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "y_test_rescaled = scaler.inverse_transform(y_test)\n",
    "\n",
    "plt.plot(df_city['date'].iloc[-len(y_test_rescaled):], y_test_rescaled, label='Rzeczywiste wartości')\n",
    "plt.plot(df_city['date'].iloc[-len(predictions_rescaled):], predictions_rescaled, label='Prognozy')\n",
    "plt.legend()\n",
    "plt.title(\"Porównanie prognoz i rzeczywistych wartości — LSTM 2 warstwy\")\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Średnia temperatura\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "825e1c1562b79b54",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T22:29:07.233140Z",
     "start_time": "2026-01-14T22:26:40.952480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Funkcja budująca model LSTM z 2 warstwami i Dropout\n",
    "# =========================\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    # Pierwsza warstwa LSTM zwracająca sekwencję\n",
    "    model.add(LSTM(units=64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Druga warstwa LSTM zwracająca tylko ostatnią wartość\n",
    "    model.add(LSTM(units=32, return_sequences=False))\n",
    "    # Warstwa wyjściowa\n",
    "    model.add(Dense(1))\n",
    "    # Kompilacja\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# Time Series Cross-Validation\n",
    "# =========================\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "rmse_scores = []\n",
    "mae_scores  = []\n",
    "mse_scores  = []\n",
    "r2_scores   = []\n",
    "\n",
    "fold = 1\n",
    "\n",
    "for train_index, test_index in tscv.split(sequences_scaled):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "\n",
    "    X_train = sequences_scaled[train_index]\n",
    "    X_test  = sequences_scaled[test_index]\n",
    "\n",
    "    y_train = labels_scaled[train_index]\n",
    "    y_test  = labels_scaled[test_index]\n",
    "\n",
    "    model = build_lstm_model(input_shape=(X_train.shape[1], 1))\n",
    "\n",
    "    # =========================\n",
    "    # EarlyStopping\n",
    "    # =========================\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=100,           # EarlyStopping zatrzyma trening wcześniej\n",
    "        batch_size=32,\n",
    "        verbose=0,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stop],\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Odwrócenie skalowania\n",
    "    y_test_rescaled = scaler.inverse_transform(y_test)\n",
    "    y_pred_rescaled = scaler.inverse_transform(y_pred)\n",
    "\n",
    "    mse  = mean_squared_error(y_test_rescaled, y_pred_rescaled)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae  = mean_absolute_error(y_test_rescaled, y_pred_rescaled)\n",
    "    r2   = r2_score(y_test_rescaled, y_pred_rescaled)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "    print(\n",
    "        f\"R²: {r2:.4f} | \"\n",
    "        f\"MAE: {mae:.4f} | \"\n",
    "        f\"MSE: {mse:.4f} | \"\n",
    "        f\"RMSE: {rmse:.4f}\"\n",
    "    )\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# =========================\n",
    "# Podsumowanie wyników\n",
    "# =========================\n",
    "print(\"\\nWalk-Forward Cross-Validation — LSTM (2 warstwy + EarlyStopping)\")\n",
    "print(f\"R²   : {np.mean(r2_scores):.4f}\")\n",
    "print(f\"MAE  : {np.mean(mae_scores):.4f}\")\n",
    "print(f\"MSE  : {np.mean(mse_scores):.4f}\")\n",
    "print(f\"RMSE : {np.mean(rmse_scores):.4f}\")\n"
   ],
   "id": "8c79810f245a2883",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T22:29:15.473192Z",
     "start_time": "2026-01-14T22:29:14.978801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Predykcja na zbiorze testowym\n",
    "# =========================\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Odwrócenie skalowania\n",
    "predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "y_test_rescaled = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Dopasowanie długości (czasem w LSTM występuje różnica długości)\n",
    "min_len = min(len(y_test_rescaled), len(predictions_rescaled))\n",
    "y_test_rescaled = y_test_rescaled[:min_len]\n",
    "predictions_rescaled = predictions_rescaled[:min_len]\n",
    "\n",
    "# =========================\n",
    "# Obliczenie residuals\n",
    "# =========================\n",
    "residuals = y_test_rescaled - predictions_rescaled\n",
    "\n",
    "# =========================\n",
    "# Wykres residuals w czasie\n",
    "# =========================\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(\n",
    "    df_city['date'].iloc[-len(residuals):],\n",
    "    residuals,\n",
    "    marker='o',\n",
    "    linestyle='-',\n",
    "    color='b'\n",
    ")\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('Residuals modelu LSTM (2 warstwy) — błąd predykcji w czasie')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Błąd predykcji (°C)')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# Histogram residuals\n",
    "# =========================\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(residuals, kde=True, color='b')\n",
    "plt.title('Rozkład residuals modelu LSTM (2 warstwy)')\n",
    "plt.xlabel('Błąd predykcji (°C)')\n",
    "plt.ylabel('Częstość')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "b6c649d11a8ae599",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T22:20:40.626267Z",
     "start_time": "2026-01-14T22:20:40.623511Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6d61a2c892d35c2b",
   "execution_count": 10,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
